# Diabetes Prediction Workflow

**Author:** Trojan3877  
**Date:** 2025-06-06  

This notebook walks through:  
1. Loading & Preprocessing Data  
2. Exploratory Data Analysis (EDA)  
3. Model Training (Logistic Regression & Random Forest)  
4. Model Evaluation (Confusion Matrix & ROC Curve)  
5. Saving Outputs (images + metrics)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yaml

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    confusion_matrix,
    RocCurveDisplay
)

# Load config
with open("../config/config_sample.yaml", "r") as f:
    config = yaml.safe_load(f)

DATA_PATH = config["data"]["train_csv"]
TEST_SIZE = config["data"]["test_size"]
RANDOM_SEED = config["data"]["random_seed"]

df = pd.read_csv(DATA_PATH)
df.head()

df.info()
df.describe()
# Check for zeros in critical columns (glucose, blood pressure, BMI)
(df[["Glucose", "BloodPressure", "BMI"]] == 0).sum()

def clean_missing_values(df):
    df_clean = df.copy()
    # Replace zeros in certain columns with median
    cols = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
    for col in cols:
        median = df_clean[df_clean[col] != 0][col].median()
        df_clean[col] = df_clean[col].replace(0, median)
    return df_clean

df_clean = clean_missing_values(df)
df_clean.head()

# Histogram of Age
plt.figure(figsize=(6, 4))
sns.histplot(df_clean["Age"], bins=20)
plt.title("Age Distribution")
plt.show()

# Correlation Heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(df_clean.corr(), annot=True, cmap="coolwarm")
plt.title("Feature Correlation Matrix")
plt.show()

X = df_clean.drop("Outcome", axis=1)
y = df_clean["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED
)

X_train.shape, X_test.shape

lr_params = config["model"]["logistic_regression"]
lr = LogisticRegression(
    C=lr_params["C"],
    max_iter=lr_params["max_iter"],
    random_state=RANDOM_SEED
)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
y_proba_lr = lr.predict_proba(X_test)[:, 1]

rf_params = config["model"]["random_forest"]
rf = RandomForestClassifier(
    n_estimators=rf_params["n_estimators"],
    max_depth=rf_params["max_depth"],
    random_state=RANDOM_SEED
)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
y_proba_rf = rf.predict_proba(X_test)[:, 1]

def evaluate_model(name, y_true, y_pred, y_proba):
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred)
    rec = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    roc_auc = roc_auc_score(y_true, y_proba)
    return {"Model": name, "Accuracy": acc, "Precision": prec, 
            "Recall": rec, "F1-Score": f1, "ROC-AUC": roc_auc}

results = []
results.append(evaluate_model("Logistic Regression", y_test, y_pred_lr, y_proba_lr))
results.append(evaluate_model("Random Forest", y_test, y_pred_rf, y_proba_rf))

results_df = pd.DataFrame(results).round(3)
results_df

# Choose Random Forest (example) for visualization
cm = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix – Random Forest")
plt.savefig("../docs/confusion_matrix.png", bbox_inches="tight")
plt.show()

# ROC Curve
RocCurveDisplay.from_estimator(rf, X_test, y_test)
plt.title("ROC Curve – Random Forest")
plt.savefig("../docs/roc_curve.png", bbox_inches="tight")
plt.show()

## Interpretation

- **Random Forest** outperforms Logistic Regression on most metrics (accuracy: 0.82 vs. 0.78, ROC-AUC: 0.86 vs. 0.82).
- High recall (~0.77) indicates fewer false negatives—useful for early diabetes detection.

### Next Steps

1. Hyperparameter tuning with cross-validation (e.g., GridSearchCV).  
2. Explore additional models (XGBoost, SVM).  
3. Deploy best model (e.g., AWS SageMaker endpoint).  
4. Integrate feature importance plots.  
